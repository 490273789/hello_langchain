# LangChain Model I/O - Prompt å­¦ä¹ ç¬”è®°

## æ¦‚è¿°

Model I/O æ˜¯ LangChain ä¸­ä¸è¯­è¨€æ¨¡å‹äº¤äº’çš„æ ¸å¿ƒæ¨¡å—ï¼Œä¸»è¦åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼š
- **Promptsï¼ˆæç¤ºè¯ï¼‰**: æ¨¡æ¿åŒ–æ¨¡å‹è¾“å…¥
- **Language Modelsï¼ˆè¯­è¨€æ¨¡å‹ï¼‰**: é€šè¿‡é€šç”¨æ¥å£è°ƒç”¨è¯­è¨€æ¨¡å‹
- **Output Parsersï¼ˆè¾“å‡ºè§£æå™¨ï¼‰**: ä»æ¨¡å‹è¾“å‡ºä¸­æå–ä¿¡æ¯

æœ¬ç¬”è®°é‡ç‚¹æ€»ç»“ Prompt ç›¸å…³çŸ¥è¯†ã€‚

---

## Prompt Template ç±»å‹æ€»è§ˆ

LangChain æä¾›äº†å¤šç§ Prompt Template ç±»å‹ï¼š

| æ¨¡æ¿ç±»å‹ | ç”¨é€” | é€‚ç”¨åœºæ™¯ |
|---------|------|---------|
| `PromptTemplate` | åŸºç¡€å­—ç¬¦ä¸²æ¨¡æ¿ | ç®€å•çš„æ–‡æœ¬æç¤ºè¯ |
| `ChatPromptTemplate` | å¯¹è¯æ¶ˆæ¯æ¨¡æ¿ | å¤šè½®å¯¹è¯ã€è§’è‰²è®¾å®š |
| `MessagesPlaceholder` | æ¶ˆæ¯å ä½ç¬¦ | åŠ¨æ€æ’å…¥å¯¹è¯å†å² |
| `FewShotPromptTemplate` | å°‘æ ·æœ¬å­¦ä¹ æ¨¡æ¿ | æä¾›ç¤ºä¾‹å¼•å¯¼æ¨¡å‹ |
| `FewShotChatMessagePromptTemplate` | å¯¹è¯å¼å°‘æ ·æœ¬æ¨¡æ¿ | å¯¹è¯åœºæ™¯ä¸‹çš„å°‘æ ·æœ¬å­¦ä¹  |
| `PipelinePromptTemplate` | ç®¡é“æ¨¡æ¿ | ç»„åˆå¤ç”¨å¤šä¸ªæ¨¡æ¿ |
| `HumanMessagePromptTemplate` | ç”¨æˆ·æ¶ˆæ¯æ¨¡æ¿ | æ„å»ºç”¨æˆ·æ¶ˆæ¯ |
| `SystemMessagePromptTemplate` | ç³»ç»Ÿæ¶ˆæ¯æ¨¡æ¿ | æ„å»ºç³»ç»Ÿæ¶ˆæ¯ |
| `AIMessagePromptTemplate` | AIæ¶ˆæ¯æ¨¡æ¿ | æ„å»ºAIæ¶ˆæ¯ |

---

## 1. æ¶ˆæ¯ç±»å‹ï¼ˆMessagesï¼‰

LangChain æ”¯æŒå¤šç§æ¶ˆæ¯ç±»å‹ï¼Œç”¨äºæ„å»ºä¸å¤§æ¨¡å‹çš„å¯¹è¯ï¼š

### 1.1 æ¶ˆæ¯ç±»

```python
from langchain.messages import SystemMessage, HumanMessage, AIMessage

# SystemMessage - ç³»ç»Ÿæ¶ˆæ¯ï¼Œç”¨äºè®¾ç½®AIçš„è¡Œä¸ºå’Œè§’è‰²
system_msg = SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¸®ç”¨æˆ·è§£å†³é—®é¢˜ï¼Œä½ çš„åå­—å«ä¸€æŠŠæ‰‹")

# HumanMessage - ç”¨æˆ·æ¶ˆæ¯
human_msg = HumanMessage(content="ä½ æ˜¯è°ï¼Ÿ")

# AIMessage - AIçš„å›å¤æ¶ˆæ¯
ai_msg = AIMessage(content="æˆ‘æ˜¯ä¸€æŠŠæ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼")
```

### 1.2 æ¶ˆæ¯æ„å»ºæ–¹å¼

**æ–¹å¼ä¸€ï¼šä½¿ç”¨æ¶ˆæ¯ç±»åˆ—è¡¨**
```python
from langchain.messages import SystemMessage, HumanMessage

messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹"),
    HumanMessage(content="ä½ æ˜¯è°ï¼Ÿ"),
]
response = model.invoke(messages)
```

**æ–¹å¼äºŒï¼šä½¿ç”¨å­—å…¸æ ¼å¼ï¼ˆOpenAI å…¼å®¹æ ¼å¼ï¼‰**
```python
messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹"},
    {"role": "user", "content": "ä½ æ˜¯è°ï¼Ÿ"},
]
response = model.invoke(messages)
```

**æ–¹å¼ä¸‰ï¼šç›´æ¥ä½¿ç”¨æ–‡æœ¬ï¼ˆç®€å•åœºæ™¯ï¼‰**
```python
# é€‚ç”¨äºå•æ¬¡ç‹¬ç«‹è¯·æ±‚ï¼Œä¸éœ€è¦å¯¹è¯å†å²
response = model.invoke("å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—")
```

### 1.3 æ¶ˆæ¯è§’è‰²è¯´æ˜

| è§’è‰² | ç±» | å­—å…¸roleå€¼ | è¯´æ˜ |
|------|-----|----------|------|
| ç³»ç»Ÿ | `SystemMessage` | `system` | è®¾ç½®AIçš„è¡Œä¸ºå’Œè§’è‰² |
| ç”¨æˆ· | `HumanMessage` | `user`/`human` | ç”¨æˆ·çš„è¾“å…¥ |
| AI | `AIMessage` | `assistant`/`ai` | AIçš„å›å¤ |

---

## 2. PromptTemplate - åŸºç¡€æç¤ºè¯æ¨¡æ¿

**æ ¸å¿ƒæ¦‚å¿µ**: æ¨¡æ¿ + å˜é‡å€¼ = å®Œæ•´çš„æç¤ºè¯

### 2.1 åˆ›å»º PromptTemplate

**æ–¹å¼ä¸€ï¼šç›´æ¥å®ä¾‹åŒ–**
```python
from langchain_core.prompts import PromptTemplate

template = PromptTemplate(
    template="ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·å°†{content}ç¿»è¯‘æˆè¯­è¨€ï¼š{lang}",
    input_variables=["content", "lang"],
)
```

**æ–¹å¼äºŒï¼šä½¿ç”¨ç±»æ–¹æ³• `from_template`ï¼ˆæ¨èï¼‰**
```python
template = PromptTemplate.from_template(
    template="ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·å°†{content}ç¿»è¯‘æˆè¯­è¨€ï¼š{lang}",
)
```

> ğŸ’¡ ä½¿ç”¨ `from_template` æ–¹æ³•ä¼šè‡ªåŠ¨æ¨æ–­ `input_variables`ï¼Œæ— éœ€æ‰‹åŠ¨æŒ‡å®šã€‚

### 2.2 ä½¿ç”¨ PromptTemplate

**è°ƒç”¨æ–¹å¼ä¸€ï¼š`format()` æ–¹æ³•**
```python
prompt = template.format(content="ä½ å¥½", lang="æ³•è¯­")
print(prompt)
# è¾“å‡ºï¼šä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·å°†ä½ å¥½ç¿»è¯‘æˆè¯­è¨€ï¼šæ³•è¯­
```

**è°ƒç”¨æ–¹å¼äºŒï¼š`invoke()` æ–¹æ³•**
```python
result = template.invoke({"content": "ä½ å¥½", "lang": "æ³•è¯­"})

# è½¬æ¢ä¸ºå­—ç¬¦ä¸²
print(result.to_string())

# è½¬æ¢ä¸ºæ¶ˆæ¯åˆ—è¡¨
print(result.to_messages())
```

### 2.3 æ¨¡æ¿æ ¼å¼

LangChain æ”¯æŒä¸¤ç§æ¨¡æ¿æ ¼å¼ï¼š

**f-string æ ¼å¼ï¼ˆé»˜è®¤ï¼‰**
```python
template = PromptTemplate.from_template("Hello, {name}!")
```

**Mustache æ ¼å¼**
```python
template = PromptTemplate.from_template(
    "Hello, {{name}}!",
    template_format="mustache"
)
```

### 2.4 éƒ¨åˆ†å˜é‡ï¼ˆPartial Variablesï¼‰

é¢„å…ˆå¡«å……éƒ¨åˆ†å˜é‡ï¼Œåç»­åªéœ€æä¾›å‰©ä½™å˜é‡ï¼š

```python
template = PromptTemplate(
    template="ä½ æ˜¯{role}ï¼Œè¯·ç”¨{lang}å›ç­”é—®é¢˜ï¼š{question}",
    input_variables=["question"],
    partial_variables={"role": "ä¸€ä¸ªAIåŠ©æ‰‹", "lang": "ä¸­æ–‡"}
)

# ä½¿ç”¨æ—¶åªéœ€æä¾› question
prompt = template.format(question="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
```

---

## 3. ChatPromptTemplate - å¯¹è¯æç¤ºè¯æ¨¡æ¿

ä¸“é—¨ç”¨äºæ„å»ºå¤šè½®å¯¹è¯çš„æç¤ºè¯æ¨¡æ¿ã€‚

### 3.1 åˆ›å»º ChatPromptTemplate

**æ–¹å¼ä¸€ï¼šä½¿ç”¨å…ƒç»„åˆ—è¡¨**
```python
from langchain_core.prompts import ChatPromptTemplate

chat_prompt = ChatPromptTemplate([
    ("system", "ä½ æ˜¯æˆ‘çš„å°åŠ©æ‰‹ï¼Œä½ å«{name}"),
    ("human", "ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ")
])
```

**æ–¹å¼äºŒï¼šä½¿ç”¨ `from_messages` æ–¹æ³•**
```python
chat_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    ("human", "è¯·ä»‹ç»ä¸€ä¸‹{topic}")
])
```

### 3.2 ä½¿ç”¨ ChatPromptTemplate

```python
# æ ¼å¼åŒ–æç¤ºè¯
prompt = chat_prompt.format_prompt(name="å°å—")

# è½¬æ¢ä¸ºæ¶ˆæ¯åˆ—è¡¨
messages = prompt.to_messages()
print(messages)
# è¾“å‡ºï¼š[SystemMessage(content='ä½ æ˜¯æˆ‘çš„å°åŠ©æ‰‹ï¼Œä½ å«å°å—'), HumanMessage(content='ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ')]
```

### 3.3 ä¸æ¨¡å‹é“¾å¼è°ƒç”¨

```python
from langchain.chat_models import init_chat_model

model = init_chat_model(model="gpt-4o-mini", model_provider="openai")

# åˆ›å»ºé“¾
chain = chat_prompt | model

# è°ƒç”¨
response = chain.invoke({"topic": "äººå·¥æ™ºèƒ½"})
```

### 3.4 å¸¸ç”¨è§’è‰²æ ‡è¯†

| è§’è‰²æ ‡è¯† | å¯¹åº”æ¶ˆæ¯ç±» | è¯´æ˜ |
|---------|-----------|------|
| `system` | `SystemMessage` | ç³»ç»ŸæŒ‡ä»¤ |
| `human`/`user` | `HumanMessage` | ç”¨æˆ·è¾“å…¥ |
| `ai`/`assistant` | `AIMessage` | AIå›å¤ |
| `placeholder` | - | ç”¨äºæ’å…¥åŠ¨æ€æ¶ˆæ¯åˆ—è¡¨ |

---

## 4. æ¶ˆæ¯æ¨¡æ¿ç±»ï¼ˆMessage Prompt Templatesï¼‰

ç”¨äºæ„å»ºå•æ¡æ¶ˆæ¯çš„æ¨¡æ¿ã€‚

### 4.1 HumanMessagePromptTemplate

```python
from langchain_core.prompts import HumanMessagePromptTemplate

human_template = HumanMessagePromptTemplate.from_template(
    "è¯·å¸®æˆ‘ç¿»è¯‘ä»¥ä¸‹å†…å®¹ï¼š{content}"
)

message = human_template.format(content="Hello World")
print(message)
# è¾“å‡ºï¼šHumanMessage(content='è¯·å¸®æˆ‘ç¿»è¯‘ä»¥ä¸‹å†…å®¹ï¼šHello World')
```

### 4.2 SystemMessagePromptTemplate

```python
from langchain_core.prompts import SystemMessagePromptTemplate

system_template = SystemMessagePromptTemplate.from_template(
    "ä½ æ˜¯ä¸€ä¸ª{role}ï¼Œä¸“æ³¨äº{domain}é¢†åŸŸ"
)

message = system_template.format(role="ä¸“å®¶", domain="æœºå™¨å­¦ä¹ ")
# è¾“å‡ºï¼šSystemMessage(content='ä½ æ˜¯ä¸€ä¸ªä¸“å®¶ï¼Œä¸“æ³¨äºæœºå™¨å­¦ä¹ é¢†åŸŸ')
```

### 4.3 AIMessagePromptTemplate

```python
from langchain_core.prompts import AIMessagePromptTemplate

ai_template = AIMessagePromptTemplate.from_template(
    "å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ å¤„ç†å…³äº{topic}çš„é—®é¢˜"
)

message = ai_template.format(topic="æ•°æ®åˆ†æ")
# è¾“å‡ºï¼šAIMessage(content='å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ å¤„ç†å…³äºæ•°æ®åˆ†æçš„é—®é¢˜')
```

### 4.4 ç»„åˆä½¿ç”¨

```python
from langchain_core.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate
)

chat_prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template("ä½ æ˜¯ä¸€ä¸ª{role}"),
    HumanMessagePromptTemplate.from_template("{question}")
])

messages = chat_prompt.format_messages(role="ç¿»è¯‘ä¸“å®¶", question="Helloç”¨ä¸­æ–‡æ€ä¹ˆè¯´ï¼Ÿ")
```

---

## 5. MessagesPlaceholder - æ¶ˆæ¯å ä½ç¬¦

ç”¨äºåœ¨æ¨¡æ¿ä¸­åŠ¨æ€æ’å…¥æ¶ˆæ¯åˆ—è¡¨ï¼Œå¸¸ç”¨äºå¯¹è¯å†å²ã€‚

### 5.1 åŸºæœ¬ç”¨æ³•

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage

prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{question}")
])

# è°ƒç”¨æ—¶ä¼ å…¥å¯¹è¯å†å²
messages = prompt.invoke({
    "history": [
        HumanMessage(content="ä½ å¥½"),
        AIMessage(content="ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ï¼Ÿ")
    ],
    "question": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
})
```

### 5.2 ç®€å†™è¯­æ³•

```python
# ä½¿ç”¨ placeholder å…ƒç»„ç®€å†™
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    ("placeholder", "{history}"),  # ç®€å†™å½¢å¼
    ("human", "{question}")
])
```

### 5.3 å¯é€‰å ä½ç¬¦

```python
# è®¾ç½®ä¸ºå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä¸ä¼šæŠ¥é”™
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹"),
    MessagesPlaceholder(variable_name="history", optional=True),
    ("human", "{question}")
])

# ä¸ä¼  history ä¹Ÿå¯ä»¥æ­£å¸¸å·¥ä½œ
messages = prompt.invoke({"question": "ä½ å¥½"})
```

### 5.4 å®Œæ•´å¯¹è¯å†å²ç¤ºä¾‹

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    MessagesPlaceholder("history"),
    ("human", "{question}")
])

result = prompt.invoke({
    "history": [
        ("human", "5 + 2 ç­‰äºå¤šå°‘"),
        ("ai", "5 + 2 ç­‰äº 7")
    ],
    "question": "å†ä¹˜ä»¥ 4 å‘¢ï¼Ÿ"
})

# è¾“å‡ºï¼š
# ChatPromptValue(messages=[
#     SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
#     HumanMessage(content="5 + 2 ç­‰äºå¤šå°‘"),
#     AIMessage(content="5 + 2 ç­‰äº 7"),
#     HumanMessage(content="å†ä¹˜ä»¥ 4 å‘¢ï¼Ÿ"),
# ])
```

---

## 6. FewShotPromptTemplate - å°‘æ ·æœ¬å­¦ä¹ æ¨¡æ¿

é€šè¿‡æä¾›ç¤ºä¾‹æ¥å¼•å¯¼æ¨¡å‹å­¦ä¹ ç‰¹å®šçš„è¾“å…¥è¾“å‡ºæ¨¡å¼ã€‚

### 6.1 åŸºæœ¬ç”¨æ³•

```python
from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate

# å®šä¹‰ç¤ºä¾‹
examples = [
    {"input": "happy", "output": "sad"},
    {"input": "tall", "output": "short"},
    {"input": "sunny", "output": "cloudy"},
]

# å®šä¹‰å•ä¸ªç¤ºä¾‹çš„æ ¼å¼æ¨¡æ¿
example_prompt = PromptTemplate(
    template="è¾“å…¥: {input}\nè¾“å‡º: {output}",
    input_variables=["input", "output"]
)

# åˆ›å»º FewShotPromptTemplate
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    prefix="ç»™å‡ºæ¯ä¸ªè¾“å…¥è¯çš„åä¹‰è¯ã€‚",
    suffix="è¾“å…¥: {word}\nè¾“å‡º:",
    input_variables=["word"]
)

prompt = few_shot_prompt.format(word="big")
print(prompt)
```

**è¾“å‡ºï¼š**
```
ç»™å‡ºæ¯ä¸ªè¾“å…¥è¯çš„åä¹‰è¯ã€‚

è¾“å…¥: happy
è¾“å‡º: sad

è¾“å…¥: tall
è¾“å‡º: short

è¾“å…¥: sunny
è¾“å‡º: cloudy

è¾“å…¥: big
è¾“å‡º:
```

### 6.2 ä½¿ç”¨ Example Selector åŠ¨æ€é€‰æ‹©ç¤ºä¾‹

æ ¹æ®è¾“å…¥åŠ¨æ€é€‰æ‹©æœ€ç›¸å…³çš„ç¤ºä¾‹ï¼š

```python
from langchain_core.prompts import FewShotPromptTemplate
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

# æ›´å¤šç¤ºä¾‹
examples = [
    {"input": "2+2", "output": "4"},
    {"input": "2+3", "output": "5"},
    {"input": "2+4", "output": "6"},
    {"input": "What is 2+2?", "output": "4"},
    {"input": "What is 2+3?", "output": "5"},
]

# åˆ›å»ºè¯­ä¹‰ç›¸ä¼¼åº¦é€‰æ‹©å™¨
example_selector = SemanticSimilarityExampleSelector.from_examples(
    examples,
    OpenAIEmbeddings(),
    Chroma,
    k=2  # é€‰æ‹©æœ€ç›¸ä¼¼çš„2ä¸ªç¤ºä¾‹
)

few_shot_prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="ä½ æ˜¯ä¸€ä¸ªè®¡ç®—å™¨ã€‚",
    suffix="è¾“å…¥: {input}\nè¾“å‡º:",
    input_variables=["input"]
)
```

---

## 7. FewShotChatMessagePromptTemplate - å¯¹è¯å¼å°‘æ ·æœ¬æ¨¡æ¿

ä¸“é—¨ä¸º Chat æ¨¡å‹è®¾è®¡çš„å°‘æ ·æœ¬å­¦ä¹ æ¨¡æ¿ã€‚

### 7.1 å›ºå®šç¤ºä¾‹

```python
from langchain_core.prompts import (
    FewShotChatMessagePromptTemplate,
    ChatPromptTemplate
)

# å®šä¹‰ç¤ºä¾‹
examples = [
    {"input": "2+2", "output": "4"},
    {"input": "2+3", "output": "5"},
]

# å®šä¹‰ç¤ºä¾‹æ ¼å¼ï¼ˆå¯¹è¯å½¢å¼ï¼‰
example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "{output}")
])

# åˆ›å»ºå°‘æ ·æœ¬æ¨¡æ¿
few_shot_prompt = FewShotChatMessagePromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
)

# ç»„åˆæˆå®Œæ•´çš„å¯¹è¯æ¨¡æ¿
final_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹"),
    few_shot_prompt,
    ("human", "{input}")
])

# ä½¿ç”¨
messages = final_prompt.format_messages(input="4+4ç­‰äºå¤šå°‘ï¼Ÿ")
```

### 7.2 åŠ¨æ€ç¤ºä¾‹é€‰æ‹©

```python
from langchain_core.prompts import (
    FewShotChatMessagePromptTemplate,
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    AIMessagePromptTemplate
)
from langchain_core.example_selectors import SemanticSimilarityExampleSelector

# ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦é€‰æ‹©å™¨
example_selector = SemanticSimilarityExampleSelector.from_examples(
    examples,
    embeddings,
    vectorstore_cls,
    k=2
)

few_shot_prompt = FewShotChatMessagePromptTemplate(
    input_variables=["input"],
    example_selector=example_selector,
    example_prompt=(
        HumanMessagePromptTemplate.from_template("{input}") +
        AIMessagePromptTemplate.from_template("{output}")
    ),
)

# å®Œæ•´æ¨¡æ¿
final_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    few_shot_prompt,
    ("human", "{input}")
])
```

---

## 8. PipelinePromptTemplate - ç®¡é“æ¨¡æ¿

ç”¨äºç»„åˆå’Œå¤ç”¨å¤šä¸ªæç¤ºè¯æ¨¡æ¿ã€‚

### 8.1 åŸºæœ¬æ¦‚å¿µ

PipelinePromptTemplate å…è®¸å°†å¤šä¸ªæ¨¡æ¿ç»„åˆåœ¨ä¸€èµ·ï¼Œå‰ä¸€ä¸ªæ¨¡æ¿çš„è¾“å‡ºå¯ä»¥ä½œä¸ºåä¸€ä¸ªæ¨¡æ¿çš„è¾“å…¥ã€‚

### 8.2 ä½¿ç”¨ç¤ºä¾‹

```python
from langchain_core.prompts import PromptTemplate, PipelinePromptTemplate

# å®šä¹‰å­æ¨¡æ¿
introduction_template = PromptTemplate.from_template(
    "ä½ æ˜¯ä¸€ä¸ª{role}ã€‚"
)

example_template = PromptTemplate.from_template(
    """è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å¯¹è¯ï¼š
ç”¨æˆ·ï¼š{example_q}
åŠ©æ‰‹ï¼š{example_a}"""
)

start_template = PromptTemplate.from_template(
    """ç°åœ¨ï¼Œè¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
ç”¨æˆ·ï¼š{input}
åŠ©æ‰‹ï¼š"""
)

# æœ€ç»ˆæ¨¡æ¿
final_template = PromptTemplate.from_template(
    """{introduction}

{example}

{start}"""
)

# åˆ›å»ºç®¡é“æ¨¡æ¿
pipeline_prompt = PipelinePromptTemplate(
    final_prompt=final_template,
    pipeline_prompts=[
        ("introduction", introduction_template),
        ("example", example_template),
        ("start", start_template)
    ]
)

# ä½¿ç”¨
prompt = pipeline_prompt.format(
    role="ç¿»è¯‘ä¸“å®¶",
    example_q="Hello",
    example_a="ä½ å¥½",
    input="Good morning"
)
```

**è¾“å‡ºï¼š**
```
ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘ä¸“å®¶ã€‚

è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å¯¹è¯ï¼š
ç”¨æˆ·ï¼šHello
åŠ©æ‰‹ï¼šä½ å¥½

ç°åœ¨ï¼Œè¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
ç”¨æˆ·ï¼šGood morning
åŠ©æ‰‹ï¼š
```

### 8.3 åº”ç”¨åœºæ™¯

- æ¨¡æ¿å¤ç”¨ï¼šå°†å¸¸ç”¨çš„æ¨¡æ¿ç‰‡æ®µç‹¬ç«‹å‡ºæ¥
- æ¨¡å—åŒ–ç®¡ç†ï¼šä¸åŒéƒ¨åˆ†å¯ä»¥ç‹¬ç«‹ä¿®æ”¹
- æ¡ä»¶ç»„åˆï¼šæ ¹æ®åœºæ™¯é€‰æ‹©ä¸åŒçš„å­æ¨¡æ¿

---

## 9. æ¨¡å‹è°ƒç”¨æ–¹å¼

### 4.1 è·å–æ¨¡å‹å®ä¾‹

```python
from langchain.chat_models import init_chat_model

# è°ƒç”¨ OpenAI
model = init_chat_model(model="gpt-4o-mini", model_provider="openai")

# è°ƒç”¨ DeepSeek
model = init_chat_model(model="deepseek-chat", model_provider="deepseek")
```

### 4.2 è°ƒç”¨æ–¹å¼å¯¹æ¯”

| è°ƒç”¨æ–¹å¼ | æ–¹æ³• | ç‰¹ç‚¹ |
|---------|------|------|
| éæµå¼è°ƒç”¨ | `invoke()` | ç­‰å¾…å®Œæ•´å“åº”è¿”å› |
| æµå¼è°ƒç”¨ | `stream()` | è¿”å›ç”Ÿæˆå™¨ï¼Œé€æ­¥è·å–å“åº” |
| æ‰¹æ¬¡è°ƒç”¨ | `batch()` | å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†å¤šä¸ªè¯·æ±‚ |
| å¼‚æ­¥è°ƒç”¨ | `ainvoke()` | åç¨‹æ–¹å¼ï¼Œå•çº¿ç¨‹é«˜å¹¶å‘ |

**éæµå¼è°ƒç”¨**
```python
response = model.invoke(messages)
print(response.content)
```

**æµå¼è°ƒç”¨**
```python
for chunk in model.stream("ä½ æ˜¯è°ï¼Ÿ"):
    print(chunk.content, end="")
```

**æ‰¹æ¬¡è°ƒç”¨**
```python
messages_list = [
    [{"role": "user", "content": "å†™ä¸€å¥å…³äºæ˜¥å¤©çš„è¯—ã€‚"}],
    [{"role": "user", "content": "å†™ä¸€å¥å…³äºå¤å¤©çš„è¯—ã€‚"}],
    [{"role": "user", "content": "å†™ä¸€å¥å…³äºç§‹å¤©çš„è¯—ã€‚"}],
]
responses = model.batch(messages_list)
```

**å¼‚æ­¥è°ƒç”¨**
```python
import asyncio

async def gather_task(messages: list):
    tasks = [model.ainvoke(message) for message in messages]
    res = await asyncio.gather(*tasks)
    return res

await gather_task(messages_list)
```

---

## 10. åŠ¨æ€æç¤ºè¯ï¼ˆé«˜çº§ç”¨æ³•ï¼‰

åœ¨ LangChain Agent ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ä¸­é—´ä»¶åŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ï¼š

```python
from langchain.agents import create_agent
from langchain.agents.middleware import dynamic_prompt, ModelRequest
from typing import TypedDict

class Context(TypedDict):
    user_role: str

@dynamic_prompt
def user_role_prompt(request: ModelRequest) -> str:
    """æ ¹æ®ç”¨æˆ·è§’è‰²ç”Ÿæˆä¸åŒçš„ç³»ç»Ÿæç¤ºè¯"""
    user_role = request.runtime.context.get("user_role", "user")
    base_prompt = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"
    
    if user_role == "expert":
        return f"{base_prompt} è¯·æä¾›è¯¦ç»†çš„æŠ€æœ¯å“åº”ã€‚"
    elif user_role == "beginner":
        return f"{base_prompt} è¯·ç”¨ç®€å•çš„è¯­è¨€è§£é‡Šï¼Œé¿å…ä½¿ç”¨æœ¯è¯­ã€‚"
    
    return base_prompt

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    middleware=[user_role_prompt],
    context_schema=Context
)
```

---

## 11. æœ€ä½³å®è·µ

### 11.1 æç¤ºè¯è®¾è®¡åŸåˆ™

1. **æ˜ç¡®è§’è‰²**: ä½¿ç”¨ SystemMessage æ¸…æ™°å®šä¹‰ AI çš„è§’è‰²å’Œè¡Œä¸º
2. **å…·ä½“æŒ‡ä»¤**: æä¾›å…·ä½“ã€æ¸…æ™°çš„ä»»åŠ¡æŒ‡ä»¤
3. **æä¾›ç¤ºä¾‹**: å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œå¯ä»¥æä¾›å°‘é‡ç¤ºä¾‹ï¼ˆFew-shot learningï¼‰
4. **è®¾ç½®è¾¹ç•Œ**: æ˜ç¡®å‘Šè¯‰ AI ä¸åº”è¯¥åšä»€ä¹ˆ

### 11.2 æ¨¡æ¿ä½¿ç”¨å»ºè®®

1. ä½¿ç”¨ `from_template` æ–¹æ³•åˆ›å»ºæ¨¡æ¿ï¼Œè‡ªåŠ¨æ¨æ–­å˜é‡
2. å¯¹äºå¤šè½®å¯¹è¯ï¼Œä½¿ç”¨ `ChatPromptTemplate`
3. å°†å¸¸ç”¨æç¤ºè¯å®šä¹‰ä¸ºå¸¸é‡ï¼Œä¾¿äºå¤ç”¨

```python
TRANSLATOR_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚
è¯·å°†ä»¥ä¸‹å†…å®¹ç¿»è¯‘æˆ{target_lang}ï¼š

{content}

è¦æ±‚ï¼š
1. ä¿æŒåŸæ„
2. ä½¿ç”¨åœ°é“çš„è¡¨è¾¾
3. æ³¨æ„è¯­æ³•æ­£ç¡®
"""

template = PromptTemplate.from_template(TRANSLATOR_PROMPT)
```

### 11.3 å®‰å…¨è€ƒè™‘

å¯¹äºæ¶‰åŠæ•°æ®åº“æ“ä½œç­‰æ•æ„Ÿä»»åŠ¡ï¼Œåœ¨æç¤ºè¯ä¸­æ˜ç¡®å®‰å…¨çº¦æŸï¼š

```python
system_prompt = """
ä½ æ˜¯ä¸€ä¸ªæ•°æ®åº“æŸ¥è¯¢åŠ©æ‰‹ã€‚
æ³¨æ„ï¼šç¦æ­¢æ‰§è¡Œä»»ä½• DML è¯­å¥ï¼ˆINSERT, UPDATE, DELETE, DROP ç­‰ï¼‰ã€‚
åœ¨æ‰§è¡ŒæŸ¥è¯¢å‰ï¼Œè¯·å…ˆæ£€æŸ¥è¡¨ç»“æ„ã€‚
"""
```

---

## 12. å¸¸ç”¨ç±»å’Œæ–¹æ³•é€ŸæŸ¥

| ç±»/æ–¹æ³• | ç”¨é€” |
|---------|------|
| `PromptTemplate` | åˆ›å»ºåŸºç¡€å­—ç¬¦ä¸²æç¤ºè¯æ¨¡æ¿ |
| `ChatPromptTemplate` | åˆ›å»ºå¯¹è¯æç¤ºè¯æ¨¡æ¿ |
| `MessagesPlaceholder` | åŠ¨æ€æ’å…¥æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¦‚å¯¹è¯å†å²ï¼‰ |
| `FewShotPromptTemplate` | å°‘æ ·æœ¬å­¦ä¹ æ¨¡æ¿ï¼ˆå­—ç¬¦ä¸²ç‰ˆï¼‰ |
| `FewShotChatMessagePromptTemplate` | å°‘æ ·æœ¬å­¦ä¹ æ¨¡æ¿ï¼ˆå¯¹è¯ç‰ˆï¼‰ |
| `PipelinePromptTemplate` | ç»„åˆå¤šä¸ªæ¨¡æ¿ |
| `HumanMessagePromptTemplate` | æ„å»ºç”¨æˆ·æ¶ˆæ¯æ¨¡æ¿ |
| `SystemMessagePromptTemplate` | æ„å»ºç³»ç»Ÿæ¶ˆæ¯æ¨¡æ¿ |
| `AIMessagePromptTemplate` | æ„å»ºAIæ¶ˆæ¯æ¨¡æ¿ |
| `SystemMessage` | ç³»ç»Ÿæ¶ˆæ¯ |
| `HumanMessage` | ç”¨æˆ·æ¶ˆæ¯ |
| `AIMessage` | AIæ¶ˆæ¯ |
| `template.format()` | å¡«å……å˜é‡ï¼Œè¿”å›å­—ç¬¦ä¸² |
| `template.invoke()` | å¡«å……å˜é‡ï¼Œè¿”å› PromptValue |
| `prompt.to_string()` | è½¬æ¢ä¸ºå­—ç¬¦ä¸² |
| `prompt.to_messages()` | è½¬æ¢ä¸ºæ¶ˆæ¯åˆ—è¡¨ |

---

## å‚è€ƒèµ„æ–™

- [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- [LangChain Prompt Templates](https://python.langchain.com/docs/modules/model_io/prompts/)
